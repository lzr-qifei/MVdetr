logs/multiviewx/aug_deform_trans_w_dec_lr0.0001_baseR0.1_neck128_out0_alpha1.0_id0_drop0.0_dropcam0.0_worldRK4_10_imgRK12_10_2024-07-11_12-59-36
Settings:
{'reID': False, 'semi_supervised': 0, 'id_ratio': 0, 'cls_thres': 0.6, 'alpha': 1.0, 'use_mse': False, 'arch': 'resnet18', 'dataset': 'multiviewx', 'num_workers': 4, 'batch_size': 1, 'dropout': 0.0, 'dropcam': 0.0, 'epochs': 100, 'lr': 0.0001, 'base_lr_ratio': 0.1, 'weight_decay': 0.0001, 'resume': None, 'visualize': False, 'seed': 2021, 'deterministic': False, 'augmentation': True, 'world_feat': 'deform_trans_w_dec', 'bottleneck_dim': 128, 'outfeat_dim': 0, 'world_reduce': 4, 'world_kernel_size': 10, 'img_reduce': 12, 'img_kernel_size': 10, 'data': '/root/autodl-tmp/MultiviewX', 'two_stage': False}
Training...
after merge:  torch.Size([1, 128, 80, 125])
dec_spatial_shapes:  tensor([[ 80, 125]], device='cuda:0')
cost_class:  tensor([[0.9640],
        [0.9592],
        [0.8712],
        [1.0546],
        [1.0608],
        [1.0886],
        [1.0555],
        [1.0766],
        [0.9529],
        [0.8929],
        [1.1856],
        [1.1828],
        [1.0169],
        [1.1285],
        [0.9190],
        [1.0799],
        [1.0249],
        [1.1151],
        [1.1336],
        [1.1003],
        [1.0212],
        [1.1873],
        [1.0127],
        [1.3599],
        [1.1025],
        [0.9710],
        [1.0225],
        [1.1052],
        [1.0801],
        [1.3458],
        [0.9097],
        [1.0391],
        [1.0407],
        [0.9557],
        [1.0110],
        [0.8476],
        [1.0649],
        [0.8912],
        [0.9114],
        [1.0500],
        [1.2137],
        [1.1391],
        [1.0063],
        [0.9180],
        [0.9971],
        [1.0918],
        [1.0759],
        [0.9950],
        [0.9169],
        [1.2100],
        [0.8829],
        [1.0884],
        [1.0423],
        [1.0469],
        [1.0451],
        [1.0247],
        [0.9950],
        [1.0819],
        [0.7275],
        [0.9952],
        [0.9599],
        [1.0325],
        [0.8695],
        [1.1069],
        [1.0254],
        [1.1056],
        [0.8788],
        [0.9314],
        [0.9071],
        [1.0284],
        [1.2581],
        [1.0929],
        [0.9233],
        [1.0253],
        [0.7414],
        [1.1253],
        [0.9501],
        [1.0945],
        [1.0327],
        [0.9880],
        [1.1175],
        [1.0336],
        [1.0504],
        [1.1358],
        [1.0772],
        [1.0034],
        [1.1114],
        [1.0925],
        [1.1432],
        [1.0116],
        [1.0978],
        [0.9996],
        [1.1666],
        [1.1232],
        [0.9754],
        [0.8993],
        [1.1334],
        [1.0326],
        [1.0066],
        [0.8139],
        [0.8469],
        [1.0779],
        [1.0761],
        [1.0892],
        [1.0309],
        [0.7972],
        [0.9307],
        [0.9323],
        [1.1675],
        [1.2160],
        [1.0615],
        [0.9134],
        [1.1822],
        [1.1641],
        [1.2994],
        [1.1339],
        [1.0105],
        [0.8853],
        [1.0087],
        [1.0222],
        [1.2941],
        [1.0777],
        [1.0975],
        [0.8875],
        [1.0547],
        [0.9593],
        [0.8187],
        [1.2047],
        [0.8964],
        [1.0218],
        [1.0330],
        [1.0840],
        [1.3042],
        [1.0810],
        [0.9068],
        [1.0736],
        [1.2610],
        [1.0506],
        [1.0666],
        [1.1890],
        [1.1912],
        [0.9659],
        [1.1001],
        [1.0017],
        [1.1092],
        [1.0730],
        [1.2604],
        [0.9125],
        [1.1761],
        [1.2578],
        [0.8356],
        [1.0874],
        [1.0264],
        [1.1328],
        [1.0508],
        [1.0578],
        [0.8102],
        [1.0589],
        [1.1412],
        [0.9162],
        [0.9945],
        [0.9790],
        [1.1068],
        [1.2302],
        [1.1702],
        [1.0990],
        [0.9610],
        [1.1233],
        [1.2069],
        [1.0164],
        [1.0614],
        [0.9513],
        [1.1779],
        [1.0421],
        [1.0070],
        [1.2755],
        [1.0854],
        [1.0914],
        [1.0433],
        [0.8334],
        [1.0291],
        [1.0242],
        [1.0798],
        [1.1574],
        [1.2142],
        [0.9131],
        [1.0989],
        [0.9334],
        [1.0459],
        [1.1596],
        [0.9305],
        [1.1046],
        [0.9467],
        [1.0103],
        [1.0919],
        [0.8668],
        [1.1970],
        [1.1388],
        [1.1395],
        [0.9441],
        [0.9634],
        [0.8250],
        [1.2370],
        [0.8440],
        [0.8069],
        [1.0878],
        [1.0095],
        [1.0305],
        [1.0374],
        [1.0051],
        [1.0325],
        [0.9291],
        [1.1468],
        [0.9879],
        [0.9245],
        [0.8735],
        [1.1811],
        [0.9952],
        [0.9016],
        [0.9094],
        [1.0764],
        [0.9874],
        [1.0530],
        [1.0849],
        [1.1470],
        [1.0592],
        [0.9864],
        [1.1000],
        [0.9649],
        [1.0826],
        [1.0436],
        [1.0499],
        [0.8543],
        [0.9994],
        [1.1603],
        [1.0225],
        [1.0145],
        [1.0478],
        [1.0689],
        [1.1011],
        [0.9950],
        [0.8024],
        [0.9081],
        [1.0519],
        [1.1924],
        [0.9512],
        [1.0077],
        [0.9998],
        [1.0693],
        [1.0624],
        [0.9465],
        [0.8758],
        [1.0783],
        [1.0791],
        [1.0918],
        [1.0555],
        [1.1852],
        [1.0971],
        [1.1504],
        [1.0160],
        [0.9605],
        [0.8805],
        [0.9597],
        [0.9183],
        [1.0561],
        [1.0478],
        [0.9119],
        [1.1042],
        [1.2419],
        [0.9677],
        [0.9264],
        [1.1761],
        [1.1017],
        [1.2257],
        [1.1306],
        [0.8996],
        [1.0857],
        [0.9609],
        [1.0158],
        [0.9331],
        [1.2171],
        [1.1932],
        [0.9828],
        [1.1297],
        [0.8850],
        [0.9594],
        [1.1425],
        [1.0534],
        [0.8516],
        [0.9084],
        [1.0970],
        [1.1504],
        [1.1892],
        [1.2090],
        [1.0590],
        [1.2620],
        [1.0262],
        [1.2279],
        [0.9576],
        [1.1956]])
indices0 shape:  39
{'labels': tensor(7.1564, device='cuda:0', grad_fn=<MulBackward0>), 'center': tensor(223.9690, device='cuda:0', grad_fn=<MseLossBackward0>)}
tensor(238.2819, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
after merge:  torch.Size([1, 128, 80, 125])
dec_spatial_shapes:  tensor([[ 80, 125]], device='cuda:0')
cost_class:  gt_cnt:  39
gt_cnt:  39
gt_cnt:  37
gt_cnt:  37
gt_cnt:  40
gt_cnt:  39
gt_cnt:  37
gt_cnt:  36
gt_cnt:  40
tensor([[1.0484],
        [1.0220],
        [0.9301],
        [1.1349],
        [1.0058],
        [1.1464],
        [1.0854],
        [0.9862],
        [0.8520],
        [1.0906],
        [1.1345],
        [1.0782],
        [1.0611],
        [1.0584],
        [1.1058],
        [0.9704],
        [0.9971],
        [1.1761],
        [1.0217],
        [1.0646],
        [1.0757],
        [1.0692],
        [0.8498],
        [1.0871],
        [0.9007],
        [0.9420],
        [0.9804],
        [1.1272],
        [0.9506],
        [1.2256],
        [1.0241],
        [1.2376],
        [0.7823],
        [0.9934],
        [0.9607],
        [1.0374],
        [0.9414],
        [1.1576],
        [1.0872],
        [0.9797],
        [1.2388],
        [1.0594],
        [0.8584],
        [1.1134],
        [1.0727],
        [1.2192],
        [1.1326],
        [1.1602],
        [0.8865],
        [0.9862],
        [0.7546],
        [1.0511],
        [0.9775],
        [1.1933],
        [1.0640],
        [0.9881],
        [1.0304],
        [1.0493],
        [0.9711],
        [1.1149],
        [1.0504],
        [1.2324],
        [0.9195],
        [0.8426],
        [0.8334],
        [1.2048],
        [1.0375],
        [0.9370],
        [0.8442],
        [1.0337],
        [1.0527],
        [1.1199],
        [1.0265],
        [0.8343],
        [0.7860],
        [1.0868],
        [1.0221],
        [0.9762],
        [1.0208],
        [1.0769],
        [1.0746],
        [1.0459],
        [1.1115],
        [1.0761],
        [0.9873],
        [1.1586],
        [1.0056],
        [0.8709],
        [1.1759],
        [1.0294],
        [0.8916],
        [0.8810],
        [1.0574],
        [1.1520],
        [1.0743],
        [1.1670],
        [1.0101],
        [1.1625],
        [0.8776],
        [0.7896],
        [0.9929],
        [0.9571],
        [0.9935],
        [1.0069],
        [1.1558],
        [0.9932],
        [0.8610],
        [1.0303],
        [1.1327],
        [1.1685],
        [0.9434],
        [1.0000],
        [1.3573],
        [1.3574],
        [0.9328],
        [1.0509],
        [0.9413],
        [0.9142],
        [1.0412],
        [1.1590],
        [1.1411],
        [1.0731],
        [0.9833],
        [0.8837],
        [0.9735],
        [1.1041],
        [0.9348],
        [1.1300],
        [1.0142],
        [0.8655],
        [1.2523],
        [1.0624],
        [1.0982],
        [1.1263],
        [0.9150],
        [0.8966],
        [1.3414],
        [1.1460],
        [0.8821],
        [0.8188],
        [1.1749],
        [1.0041],
        [1.0295],
        [1.1973],
        [1.0082],
        [1.0458],
        [1.2880],
        [1.0992],
        [0.9612],
        [1.1049],
        [1.2123],
        [1.1037],
        [1.0476],
        [1.2626],
        [0.9470],
        [0.9919],
        [1.0329],
        [1.1514],
        [1.0301],
        [1.0942],
        [1.0602],
        [0.9143],
        [0.9854],
        [1.1791],
        [1.1093],
        [1.0717],
        [1.0155],
        [1.1103],
        [1.0194],
        [0.9217],
        [0.9159],
        [0.9512],
        [0.9850],
        [1.0897],
        [1.1193],
        [1.1577],
        [1.1593],
        [1.0410],
        [0.9873],
        [0.9650],
        [1.1903],
        [0.9662],
        [1.0278],
        [1.1616],
        [1.1290],
        [0.8752],
        [1.2541],
        [1.1447],
        [1.1987],
        [1.1161],
        [0.8559],
        [1.0200],
        [0.9640],
        [0.9828],
        [0.9055],
        [0.9957],
        [1.0066],
        [1.1599],
        [0.9409],
        [1.1629],
        [1.0081],
        [0.8348],
        [1.0721],
        [0.9104],
        [0.9330],
        [0.8762],
        [0.9627],
        [1.1052],
        [0.8022],
        [0.9463],
        [0.9699],
        [1.1276],
        [1.0659],
        [1.0481],
        [0.9781],
        [0.9320],
        [1.1111],
        [1.0409],
        [0.9189],
        [1.1058],
        [1.1250],
        [0.8700],
        [0.9432],
        [1.0252],
        [1.2295],
        [0.9243],
        [0.9548],
        [1.1923],
        [0.8526],
        [0.9642],
        [0.8768],
        [1.0590],
        [0.7587],
        [1.0141],
        [0.9800],
        [1.0087],
        [0.9522],
        [1.3260],
        [0.8285],
        [1.0429],
        [1.0443],
        [0.8986],
        [0.9980],
        [1.0945],
        [1.0467],
        [1.0727],
        [1.0019],
        [0.9279],
        [0.9511],
        [1.0237],
        [0.9504],
        [0.7904],
        [1.3260],
        [1.0771],
        [0.9869],
        [0.9627],
        [1.0826],
        [1.0474],
        [0.9417],
        [1.1018],
        [0.9595],
        [0.8649],
        [1.0724],
        [0.8790],
        [1.0680],
        [1.0902],
        [1.0612],
        [1.2159],
        [1.0696],
        [0.8879],
        [0.9714],
        [1.0565],
        [0.9679],
        [1.0785],
        [1.1036],
        [1.3887],
        [1.0978],
        [0.8557],
        [1.2408],
        [1.0341],
        [1.1854],
        [0.9741],
        [1.1039],
        [0.9159],
        [0.8187],
        [1.0250],
        [1.0392],
        [1.1056],
        [0.8864],
        [0.9447],
        [0.9764],
        [1.1126],
        [1.0278],
        [1.1123],
        [1.0096],
        [1.2294],
        [1.0881],
        [1.2049],
        [1.0536],
        [0.9086]])
indices0 shape:  39
{'labels': tensor(7.0933, device='cuda:0', grad_fn=<MulBackward0>), 'center': tensor(456.1364, device='cuda:0', grad_fn=<MseLossBackward0>)}
tensor(470.3229, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
