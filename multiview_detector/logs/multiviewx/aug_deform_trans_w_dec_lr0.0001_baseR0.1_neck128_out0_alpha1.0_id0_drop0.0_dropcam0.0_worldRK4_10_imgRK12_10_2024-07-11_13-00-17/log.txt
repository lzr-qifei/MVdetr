logs/multiviewx/aug_deform_trans_w_dec_lr0.0001_baseR0.1_neck128_out0_alpha1.0_id0_drop0.0_dropcam0.0_worldRK4_10_imgRK12_10_2024-07-11_13-00-17
Settings:
{'reID': False, 'semi_supervised': 0, 'id_ratio': 0, 'cls_thres': 0.6, 'alpha': 1.0, 'use_mse': False, 'arch': 'resnet18', 'dataset': 'multiviewx', 'num_workers': 4, 'batch_size': 1, 'dropout': 0.0, 'dropcam': 0.0, 'epochs': 100, 'lr': 0.0001, 'base_lr_ratio': 0.1, 'weight_decay': 0.0001, 'resume': None, 'visualize': False, 'seed': 2021, 'deterministic': False, 'augmentation': True, 'world_feat': 'deform_trans_w_dec', 'bottleneck_dim': 128, 'outfeat_dim': 0, 'world_reduce': 4, 'world_kernel_size': 10, 'img_reduce': 12, 'img_kernel_size': 10, 'data': '/root/autodl-tmp/MultiviewX', 'two_stage': False}
Training...
gt_cnt:  37
gt_cnt:  40
gt_cnt:  39
gt_cnt:  37
gt_cnt:  39
gt_cnt:  39
gt_cnt:  37
gt_cnt:  36
gt_cnt:  40
after merge:  torch.Size([1, 128, 80, 125])
dec_spatial_shapes:  tensor([[ 80, 125]], device='cuda:0')
cost_class:  tensor([[0.9640],
        [0.9592],
        [0.8712],
        [1.0546],
        [1.0608],
        [1.0886],
        [1.0555],
        [1.0766],
        [0.9528],
        [0.8929],
        [1.1856],
        [1.1828],
        [1.0169],
        [1.1285],
        [0.9190],
        [1.0799],
        [1.0249],
        [1.1151],
        [1.1336],
        [1.1003],
        [1.0212],
        [1.1873],
        [1.0127],
        [1.3599],
        [1.1025],
        [0.9711],
        [1.0225],
        [1.1051],
        [1.0801],
        [1.3458],
        [0.9097],
        [1.0391],
        [1.0407],
        [0.9557],
        [1.0110],
        [0.8476],
        [1.0648],
        [0.8913],
        [0.9114],
        [1.0500],
        [1.2137],
        [1.1391],
        [1.0064],
        [0.9180],
        [0.9971],
        [1.0918],
        [1.0759],
        [0.9949],
        [0.9169],
        [1.2100],
        [0.8829],
        [1.0884],
        [1.0423],
        [1.0469],
        [1.0451],
        [1.0247],
        [0.9950],
        [1.0819],
        [0.7275],
        [0.9952],
        [0.9599],
        [1.0325],
        [0.8695],
        [1.1069],
        [1.0254],
        [1.1056],
        [0.8788],
        [0.9314],
        [0.9071],
        [1.0284],
        [1.2581],
        [1.0929],
        [0.9233],
        [1.0253],
        [0.7413],
        [1.1253],
        [0.9501],
        [1.0944],
        [1.0327],
        [0.9880],
        [1.1176],
        [1.0336],
        [1.0504],
        [1.1358],
        [1.0772],
        [1.0034],
        [1.1114],
        [1.0925],
        [1.1432],
        [1.0116],
        [1.0978],
        [0.9996],
        [1.1666],
        [1.1231],
        [0.9753],
        [0.8993],
        [1.1333],
        [1.0326],
        [1.0066],
        [0.8139],
        [0.8469],
        [1.0779],
        [1.0762],
        [1.0892],
        [1.0309],
        [0.7972],
        [0.9307],
        [0.9323],
        [1.1675],
        [1.2160],
        [1.0615],
        [0.9134],
        [1.1822],
        [1.1641],
        [1.2994],
        [1.1339],
        [1.0105],
        [0.8854],
        [1.0087],
        [1.0222],
        [1.2941],
        [1.0777],
        [1.0975],
        [0.8875],
        [1.0547],
        [0.9593],
        [0.8187],
        [1.2047],
        [0.8965],
        [1.0218],
        [1.0330],
        [1.0840],
        [1.3042],
        [1.0810],
        [0.9068],
        [1.0736],
        [1.2610],
        [1.0506],
        [1.0666],
        [1.1890],
        [1.1912],
        [0.9659],
        [1.1001],
        [1.0017],
        [1.1092],
        [1.0730],
        [1.2604],
        [0.9124],
        [1.1762],
        [1.2578],
        [0.8356],
        [1.0874],
        [1.0265],
        [1.1328],
        [1.0508],
        [1.0578],
        [0.8102],
        [1.0589],
        [1.1412],
        [0.9162],
        [0.9946],
        [0.9790],
        [1.1068],
        [1.2302],
        [1.1702],
        [1.0990],
        [0.9610],
        [1.1233],
        [1.2069],
        [1.0164],
        [1.0614],
        [0.9513],
        [1.1779],
        [1.0421],
        [1.0070],
        [1.2755],
        [1.0853],
        [1.0913],
        [1.0433],
        [0.8334],
        [1.0291],
        [1.0243],
        [1.0798],
        [1.1574],
        [1.2142],
        [0.9131],
        [1.0989],
        [0.9334],
        [1.0459],
        [1.1596],
        [0.9305],
        [1.1046],
        [0.9467],
        [1.0103],
        [1.0919],
        [0.8668],
        [1.1970],
        [1.1389],
        [1.1395],
        [0.9441],
        [0.9634],
        [0.8250],
        [1.2370],
        [0.8440],
        [0.8069],
        [1.0878],
        [1.0094],
        [1.0305],
        [1.0374],
        [1.0051],
        [1.0325],
        [0.9292],
        [1.1468],
        [0.9879],
        [0.9245],
        [0.8735],
        [1.1811],
        [0.9952],
        [0.9016],
        [0.9094],
        [1.0764],
        [0.9874],
        [1.0530],
        [1.0849],
        [1.1470],
        [1.0592],
        [0.9864],
        [1.1001],
        [0.9649],
        [1.0826],
        [1.0436],
        [1.0499],
        [0.8543],
        [0.9994],
        [1.1603],
        [1.0225],
        [1.0145],
        [1.0477],
        [1.0689],
        [1.1011],
        [0.9950],
        [0.8024],
        [0.9082],
        [1.0519],
        [1.1924],
        [0.9512],
        [1.0077],
        [0.9998],
        [1.0693],
        [1.0624],
        [0.9465],
        [0.8758],
        [1.0783],
        [1.0791],
        [1.0918],
        [1.0555],
        [1.1852],
        [1.0971],
        [1.1504],
        [1.0160],
        [0.9605],
        [0.8805],
        [0.9597],
        [0.9183],
        [1.0561],
        [1.0478],
        [0.9119],
        [1.1042],
        [1.2419],
        [0.9677],
        [0.9264],
        [1.1761],
        [1.1017],
        [1.2258],
        [1.1306],
        [0.8996],
        [1.0857],
        [0.9609],
        [1.0159],
        [0.9331],
        [1.2171],
        [1.1932],
        [0.9828],
        [1.1298],
        [0.8850],
        [0.9594],
        [1.1425],
        [1.0534],
        [0.8516],
        [0.9084],
        [1.0970],
        [1.1504],
        [1.1892],
        [1.2090],
        [1.0590],
        [1.2620],
        [1.0262],
        [1.2280],
        [0.9576],
        [1.1956]])
indices0 shape:  39
{'labels': tensor(7.1149, device='cuda:0', grad_fn=<MulBackward0>), 'center': tensor(60.5406, device='cuda:0', grad_fn=<MseLossBackward0>)}
tensor(74.7704, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
